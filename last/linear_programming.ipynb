{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68f7d3a",
   "metadata": {},
   "source": [
    "#### 최적화 문제\n",
    "* 어떤 목적함수의 함수값을 최적화(최대화 또는 최소화) 시키는 파라미터(변수) 조합을 찾는 문제\n",
    "* 일변수 함수 최적화/다변수 함수 최적화\n",
    "* 선형 최적화/비선형 최적화\n",
    "* 제약조건 여부에 따라 contrained optimization/unconstrained optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8d2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbdf36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a46317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cfdb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile regression\n",
    "# 식을 최소화하는 beta는 Linear Programming 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04b3389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 10:09:48,428 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a2f2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.read_csv(\"Cars93.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28897929",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = car_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2254118",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max.Price</th>\n",
       "      <th>MPG.city</th>\n",
       "      <th>MPG.highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn.circle</th>\n",
       "      <th>Rear.seat.room</th>\n",
       "      <th>Luggage.room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>37.7</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>39</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Eurovan</td>\n",
       "      <td>Van</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>187</td>\n",
       "      <td>115</td>\n",
       "      <td>72</td>\n",
       "      <td>38</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3960</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Eurovan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>Compact</td>\n",
       "      <td>17.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>103</td>\n",
       "      <td>67</td>\n",
       "      <td>35</td>\n",
       "      <td>31.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2985</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Passat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Corrado</td>\n",
       "      <td>Sporty</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>159</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>36</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2810</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Corrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>240</td>\n",
       "      <td>Compact</td>\n",
       "      <td>21.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.5</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>190</td>\n",
       "      <td>104</td>\n",
       "      <td>67</td>\n",
       "      <td>37</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2985</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volvo 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>850</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>24.8</td>\n",
       "      <td>26.7</td>\n",
       "      <td>28.5</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>105</td>\n",
       "      <td>69</td>\n",
       "      <td>38</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3245</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volvo 850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manufacturer    Model     Type  Min.Price  Price  Max.Price  MPG.city  \\\n",
       "0         Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1         Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2          Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3          Audi      100  Midsize       30.8   37.7       44.6        19   \n",
       "4           BMW     535i  Midsize       23.7   30.0       36.2        22   \n",
       "..          ...      ...      ...        ...    ...        ...       ...   \n",
       "88   Volkswagen  Eurovan      Van       16.6   19.7       22.7        17   \n",
       "89   Volkswagen   Passat  Compact       17.6   20.0       22.4        21   \n",
       "90   Volkswagen  Corrado   Sporty       22.9   23.3       23.7        18   \n",
       "91        Volvo      240  Compact       21.8   22.7       23.5        21   \n",
       "92        Volvo      850  Midsize       24.8   26.7       28.5        20   \n",
       "\n",
       "    MPG.highway             AirBags DriveTrain  ... Passengers  Length  \\\n",
       "0            31                None      Front  ...          5     177   \n",
       "1            25  Driver & Passenger      Front  ...          5     195   \n",
       "2            26         Driver only      Front  ...          5     180   \n",
       "3            26  Driver & Passenger      Front  ...          6     193   \n",
       "4            30         Driver only       Rear  ...          4     186   \n",
       "..          ...                 ...        ...  ...        ...     ...   \n",
       "88           21                None      Front  ...          7     187   \n",
       "89           30                None      Front  ...          5     180   \n",
       "90           25                None      Front  ...          4     159   \n",
       "91           28         Driver only       Rear  ...          5     190   \n",
       "92           28  Driver & Passenger      Front  ...          5     184   \n",
       "\n",
       "    Wheelbase  Width  Turn.circle Rear.seat.room  Luggage.room  Weight  \\\n",
       "0         102     68           37           26.5          11.0    2705   \n",
       "1         115     71           38           30.0          15.0    3560   \n",
       "2         102     67           37           28.0          14.0    3375   \n",
       "3         106     70           37           31.0          17.0    3405   \n",
       "4         109     69           39           27.0          13.0    3640   \n",
       "..        ...    ...          ...            ...           ...     ...   \n",
       "88        115     72           38           34.0           NaN    3960   \n",
       "89        103     67           35           31.5          14.0    2985   \n",
       "90         97     66           36           26.0          15.0    2810   \n",
       "91        104     67           37           29.5          14.0    2985   \n",
       "92        105     69           38           30.0          15.0    3245   \n",
       "\n",
       "     Origin                Make  \n",
       "0   non-USA       Acura Integra  \n",
       "1   non-USA        Acura Legend  \n",
       "2   non-USA             Audi 90  \n",
       "3   non-USA            Audi 100  \n",
       "4   non-USA            BMW 535i  \n",
       "..      ...                 ...  \n",
       "88  non-USA  Volkswagen Eurovan  \n",
       "89  non-USA   Volkswagen Passat  \n",
       "90  non-USA  Volkswagen Corrado  \n",
       "91  non-USA           Volvo 240  \n",
       "92  non-USA           Volvo 850  \n",
       "\n",
       "[93 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28aac148",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = car_df[['Price', 'Origin']]\n",
    "car_df = pd.get_dummies(car_df, columns=['Origin'], drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cc64982",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = car_df['Price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0261383c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.9, 33.9, 29.1, 37.7, 30. , 15.7, 20.8, 23.7, 26.3, 34.7, 40.1,\n",
       "       13.4, 11.4, 15.1, 15.9, 16.3, 16.6, 18.8, 38. , 18.4, 15.8, 29.5,\n",
       "        9.2, 11.3, 13.3, 19. , 15.6, 25.8, 12.2, 19.3,  7.4, 10.1, 11.3,\n",
       "       15.9, 14. , 19.9, 20.2, 20.9,  8.4, 12.5, 19.8, 12.1, 17.5,  8. ,\n",
       "       10. , 10. , 13.9, 47.9, 28. , 35.2, 34.3, 36.1,  8.3, 11.6, 16.5,\n",
       "       19.1, 32.5, 31.9, 61.9, 14.1, 14.9, 10.3, 26.1, 11.8, 15.7, 19.1,\n",
       "       21.5, 13.5, 16.3, 19.5, 20.7, 14.4,  9. , 11.1, 17.7, 18.5, 24.4,\n",
       "       28.7, 11.1,  8.4, 10.9, 19.5,  8.6,  9.8, 18.4, 18.2, 22.7,  9.1,\n",
       "       19.7, 20. , 23.3, 22.7, 26.7])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66c1bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_df['Origin_non-USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09207bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "     ..\n",
       "88    1\n",
       "89    1\n",
       "90    1\n",
       "91    1\n",
       "92    1\n",
       "Name: Origin_non-USA, Length: 93, dtype: uint8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3608fda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sypar\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "565de4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffbbdf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[0] ## the number of data\n",
    "p = X.shape[1] ## the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91458776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n  # 데이터 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c954e31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p  # 변량 수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fbaec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [0.1, 0.25, 0.5, 0.75, 0.9]   # 분위쉬 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e123d0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "for q in qs:\n",
    "    A_eq = np.hstack([X, -X, np.identity(n), -np.identity(n)]) \n",
    "    # hstack : 배열을 옆으로 붙임\n",
    "    # identity : n*n 정방단위행렬\n",
    "    b_eq = y\n",
    "    c = np.array([0]*(2*p) + [q]*n + [1-q]*n)\n",
    "    res = linprog(c, A_eq=A_eq, b_eq=b_eq,method='highs')\n",
    "    \n",
    "    x_plus = res.x[:p]\n",
    "    x_minus = res.x[p:2*p]\n",
    "    x = x_plus-x_minus\n",
    "    print(f'q : {q}, intercept : {x[0]}, slope : {round(x[1],3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee0cfd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f34a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "url=\"http://freakonometrics.free.fr/rent98_00.txt\"\n",
    "s=requests.get(url).content\n",
    "base=pd.read_csv(io.StringIO(s.decode('utf-8')), sep='\\t')\n",
    "\n",
    "\n",
    "tau = 0.3\n",
    "\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "X = pd.DataFrame(columns=[0,1])\n",
    "X[1] = base[\"area\"] #data points for independent variable area\n",
    "X[2] = base[\"yearc\"] #data points for independent variable year\n",
    "X[0] = 1 #intercept\n",
    "\n",
    "K = X.shape[1]\n",
    "N = X.shape[0]\n",
    "\n",
    "# equality constraints - left hand side\n",
    "\n",
    "A1 = X.to_numpy() # intercepts & data points - positive weights\n",
    "A2 = X.to_numpy() * - 1 # intercept & data points - negative weights\n",
    "A3 = np.identity(N) # error - positive\n",
    "A4 = np.identity(N)*-1 # error - negative\n",
    "\n",
    "A = np.concatenate((A1,A2,A3,A4 ), axis= 1) #all the equality constraints \n",
    "\n",
    "# equality constraints - right hand side\n",
    "b = base[\"rent_euro\"].to_numpy()\n",
    "\n",
    "#goal function - intercept & data points have 0 weights\n",
    "#positive error has tau weight, negative error has 1-tau weight\n",
    "c = np.concatenate((np.repeat(0,2*K), tau*np.repeat(1,N), (1-tau)*np.repeat(1,N) ))\n",
    "\n",
    "#converting from numpy types to cvxopt matrix\n",
    "\n",
    "Am = matrix(A)\n",
    "bm = matrix(b)\n",
    "cm = matrix(c)\n",
    "\n",
    "# all variables must be greater than zero\n",
    "# adding inequality constraints - left hand side\n",
    "n = Am.size[1]\n",
    "G = matrix(0.0, (n,n))\n",
    "G[::n+1] = -1.0\n",
    "\n",
    "# adding inequality constraints - right hand side (all zeros)\n",
    "h = matrix(0.0, (n,1))\n",
    "\n",
    "#solving the model\n",
    "sol = solvers.lp(cm,G,h,Am,bm, solver='glpk')\n",
    "\n",
    "x = sol['x']\n",
    "\n",
    "#both negative and positive components get values above zero, this gets fixed here\n",
    "beta = x[0:K] - x[K :2*K]\n",
    "\n",
    "print(beta)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36c4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196bab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a10e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asgl import ASGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef550b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASGL.sgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683aa721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ASGL:\n",
      "    def __init__(self, model, penalization, intercept=True, tol=1e-5, lambda1=1, alpha=0.5, tau=0.5,\n",
      "                 lasso_weights=None, gl_weights=None, parallel=False, num_cores=None, solver='default', max_iters=500):\n",
      "        \"\"\"\n",
      "        Parameters:\n",
      "            model: model to be fit (accepts 'lm' or 'qr')\n",
      "            penalization: penalization to use (accepts None, 'lasso', 'gl', 'sgl', 'asgl', 'asgl_lasso', 'asgl_gl',\n",
      "                          alasso, agl)\n",
      "            intercept: boolean, whether to fit the model including intercept or not\n",
      "            tol:  tolerance for a coefficient in the model to be considered as 0\n",
      "            lambda1: parameter value that controls the level of shrinkage applied on penalizations\n",
      "            alpha: parameter value, tradeoff between lasso and group lasso in sgl penalization\n",
      "            tau: quantile level in quantile regression models\n",
      "            lasso_weights: lasso weights in adaptive penalizations\n",
      "            gl_weights: group lasso weights in adaptive penalizations\n",
      "            parallel: boolean, whether to execute the code in parallel or sequentially\n",
      "            num_cores: if parallel is set to true, the number of cores to use in the execution. Default is (max - 1)\n",
      "            solver: solver to be used by CVXPY. default uses optimal alternative depending on the problem\n",
      "            max_iters: CVXPY parameter. Default is 500\n",
      "\n",
      "        Returns:\n",
      "            This is a class definition so there is no return. Main method of this class is fit,  that has no return\n",
      "            but outputs automatically to _coef.\n",
      "            ASGL._coef stores a list of regression model coefficients.\n",
      "        \"\"\"\n",
      "        self.valid_models = ['lm', 'qr']\n",
      "        self.valid_penalizations = ['lasso', 'gl', 'sgl', 'alasso', 'agl', 'asgl', 'asgl_lasso', 'asgl_gl']\n",
      "        self.model = model\n",
      "        self.penalization = penalization\n",
      "        self.intercept = intercept\n",
      "        self.tol = tol\n",
      "        self.lambda1 = lambda1\n",
      "        self.alpha = alpha\n",
      "        self.tau = tau\n",
      "        self.lasso_weights = lasso_weights\n",
      "        self.gl_weights = gl_weights\n",
      "        self.parallel = parallel\n",
      "        self.num_cores = num_cores\n",
      "        self.max_iters = max_iters\n",
      "        self.coef_ = None\n",
      "        # CVXPY solver parameters\n",
      "        self.solver_stats = None\n",
      "        self.solver = solver\n",
      "\n",
      "    # Model checker related functions #################################################################################\n",
      "\n",
      "    def _model_checker(self):\n",
      "        \"\"\"\n",
      "        Checks if the input model is one of the valid options:\n",
      "         - lm for linear models\n",
      "         - qr for quantile regression models\n",
      "        \"\"\"\n",
      "        if self.model in self.valid_models:\n",
      "            return True\n",
      "        else:\n",
      "            logging.error(f'{self.model} is not a valid model. Valid models are {self.valid_models}')\n",
      "            return False\n",
      "\n",
      "    def _penalization_checker(self):\n",
      "        \"\"\"\n",
      "        Checks if the penalization is one of the valid options:\n",
      "         - lasso for lasso penalization\n",
      "         - gl for group lasso penalization\n",
      "         - sgl for sparse group lasso penalization\n",
      "         - asgl for adaptive sparse group lasso penalization\n",
      "         - asgl_lasso for an sparse group lasso with adaptive weights in the lasso part\n",
      "         - asgl_gl for an sparse group lasso with adaptive weights in the group lasso part\n",
      "        \"\"\"\n",
      "        if (self.penalization in self.valid_penalizations) or (self.penalization is None):\n",
      "            return True\n",
      "        else:\n",
      "            logging.error(f'{self.penalization} is not a valid penalization. '\n",
      "                          f'Valid penalizations are {self.valid_penalizations} or None')\n",
      "            return False\n",
      "\n",
      "    def _dtype_checker(self):\n",
      "        \"\"\"\n",
      "        Checks if some of the inputs are in the correct format\n",
      "        \"\"\"\n",
      "        response_1 = False\n",
      "        response_2 = False\n",
      "        if isinstance(self.intercept, bool):\n",
      "            response_1 = True\n",
      "        if isinstance(self.tol, np.float):\n",
      "            response_2 = True\n",
      "        response = response_1 and response_2\n",
      "        return response\n",
      "\n",
      "    def _input_checker(self):\n",
      "        \"\"\"\n",
      "        Checks that every input parameter for the model solvers has the expected format\n",
      "        \"\"\"\n",
      "        response_list = [self._model_checker(), self._penalization_checker(), self._dtype_checker()]\n",
      "        return False not in response_list\n",
      "\n",
      "    # Preprocessing related functions #################################################################################\n",
      "\n",
      "    def _preprocessing_lambda(self):\n",
      "        \"\"\"\n",
      "        Processes the input lambda1 parameter and transforms it as required by the solver package functions\n",
      "        \"\"\"\n",
      "        n_lambda = None\n",
      "        lambda_vector = None\n",
      "        if self.penalization is not None:\n",
      "            if isinstance(self.lambda1, (np.float, np.int)):\n",
      "                lambda_vector = [self.lambda1]\n",
      "            else:\n",
      "                lambda_vector = self.lambda1\n",
      "            n_lambda = len(lambda_vector)\n",
      "        return n_lambda, lambda_vector\n",
      "\n",
      "    def _preprocessing_alpha(self):\n",
      "        \"\"\"\n",
      "        Processes the input alpha parameter from sgl and asgl penalizations and transforms it as required by the solver\n",
      "        package functions\n",
      "        \"\"\"\n",
      "        n_alpha = None\n",
      "        alpha_vector = None\n",
      "        if 'sgl' in self.penalization:\n",
      "            if self.alpha is not None:\n",
      "                if isinstance(self.alpha, (np.float, np.int)):\n",
      "                    alpha_vector = [self.alpha]\n",
      "                else:\n",
      "                    alpha_vector = self.alpha\n",
      "                n_alpha = len(alpha_vector)\n",
      "        return n_alpha, alpha_vector\n",
      "\n",
      "    def _preprocessing_weights(self, weights):\n",
      "        \"\"\"\n",
      "        Converts l_weights into a list of lists. Each list inside l_weights defines a set of weights for a model\n",
      "        \"\"\"\n",
      "        n_weights = None\n",
      "        weights_list = None\n",
      "        if self.penalization in ['asgl', 'asgl_lasso', 'asgl_gl', 'alasso', 'agl']:\n",
      "            if weights is not None:\n",
      "                if isinstance(weights, list):\n",
      "                    # If weights is a list of lists -> convert to list of arrays\n",
      "                    if isinstance(weights[0], list):\n",
      "                        weights_list = [np.asarray(elt) for elt in weights]\n",
      "                    # If weights is a list of numbers -> store in a list\n",
      "                    elif isinstance(weights[0], (np.float, np.int)):\n",
      "                        weights_list = [np.asarray(weights)]\n",
      "                    else:\n",
      "                        # If it is a list of arrays, maintain this way\n",
      "                        weights_list = weights\n",
      "                # If weights is a ndarray -> store in a list and convert into list\n",
      "                elif isinstance(weights, np.ndarray):\n",
      "                    weights_list = [weights]\n",
      "                if self.intercept:\n",
      "                    weights_list = [np.insert(elt, 0, 0, axis=0) for elt in weights_list]\n",
      "                n_weights = len(weights_list)\n",
      "        return n_weights, weights_list\n",
      "\n",
      "    def _preprocessing_itertools_param(self, lambda_vector, alpha_vector, lasso_weights_list, gl_weights_list):\n",
      "        \"\"\"\n",
      "        Receives as input the results from preprocessing_lambda, preprocessing_alpha and preprocessing_weights\n",
      "        Outputs an iterable list of parameter values \"param\"\n",
      "        \"\"\"\n",
      "        if self.penalization in ['lasso', 'gl']:\n",
      "            param = lambda_vector\n",
      "        elif self.penalization == 'sgl':\n",
      "            param = itertools.product(lambda_vector, alpha_vector)\n",
      "        elif self.penalization == 'alasso':\n",
      "            param = itertools.product(lambda_vector, lasso_weights_list)\n",
      "        elif self.penalization == 'agl':\n",
      "            param = itertools.product(lambda_vector, gl_weights_list)\n",
      "        elif 'asgl' in self.penalization:\n",
      "            param = itertools.product(lambda_vector, alpha_vector, lasso_weights_list, gl_weights_list)\n",
      "        else:\n",
      "            param = None\n",
      "            logging.error(f'Error preprocessing input parameters')\n",
      "        param = list(param)\n",
      "        return param\n",
      "\n",
      "    def _preprocessing(self):\n",
      "        \"\"\"\n",
      "        Receives all the parameters of the models and creates tuples of the parameters to be executed in the penalized\n",
      "        model solvers\n",
      "        \"\"\"\n",
      "        # Run the input_checker to verify that the inputs have the correct format\n",
      "        if self._input_checker() is False:\n",
      "            logging.error('incorrect input parameters')\n",
      "            raise ValueError('incorrect input parameters')\n",
      "        # Defines param as None for the unpenalized model\n",
      "        if self.penalization is None:\n",
      "            param = None\n",
      "        else:\n",
      "            # Reformat parameter vectors\n",
      "            n_lambda, lambda_vector = self._preprocessing_lambda()\n",
      "            n_alpha, alpha_vector = self._preprocessing_alpha()\n",
      "            n_lasso_weights, lasso_weights_list = self._preprocessing_weights(self.lasso_weights)\n",
      "            n_gl_weights, gl_weights_list = self._preprocessing_weights(self.gl_weights)\n",
      "            param = self._preprocessing_itertools_param(lambda_vector, alpha_vector, lasso_weights_list,\n",
      "                                                        gl_weights_list)\n",
      "        return param\n",
      "\n",
      "    # CVXPY SOLVER RELATED OPTIONS ###################################################################################\n",
      "\n",
      "    def _cvxpy_solver_options(self, solver):\n",
      "        if solver == 'ECOS':\n",
      "            solver_dict = dict(solver=solver,\n",
      "                               max_iters=self.max_iters)\n",
      "        elif solver == 'OSQP':\n",
      "            solver_dict = dict(solver=solver,\n",
      "                               max_iter=self.max_iters)\n",
      "        else:\n",
      "            solver_dict = dict(solver=solver)\n",
      "        return solver_dict\n",
      "\n",
      "    # SOLVERS #########################################################################################################\n",
      "\n",
      "    def _quantile_function(self, x):\n",
      "        \"\"\"\n",
      "        Quantile function required for quantile regression models.\n",
      "        \"\"\"\n",
      "        return 0.5 * cvxpy.abs(x) + (self.tau - 0.5) * x\n",
      "\n",
      "    def _num_beta_var_from_group_index(self, group_index):\n",
      "        \"\"\"\n",
      "        Internal function used in group based penalizations (gl, sgl, asgl, asgl_lasso, asgl_gl)\n",
      "        \"\"\"\n",
      "        group_sizes = []\n",
      "        beta_var = []\n",
      "        unique_group_index = np.unique(group_index)\n",
      "        # Define the objective function\n",
      "        for idx in unique_group_index:\n",
      "            group_sizes.append(len(np.where(group_index == idx)[0]))\n",
      "            beta_var.append(cvxpy.Variable(len(np.where(group_index == idx)[0])))\n",
      "        return group_sizes, beta_var\n",
      "\n",
      "    def unpenalized_solver(self, x, y):\n",
      "        n, m = x.shape\n",
      "        # If we want an intercept, it adds a column of ones to the matrix x\n",
      "        if self.intercept:\n",
      "            m = m + 1\n",
      "            x = np.c_[np.ones(n), x]\n",
      "        # Define the objective function\n",
      "        beta_var = cvxpy.Variable(m)\n",
      "        if self.model == 'lm':\n",
      "            objective_function = (1.0 / n) * cvxpy.sum_squares(y - x @ beta_var)\n",
      "        else:\n",
      "            objective_function = (1.0 / n) * cvxpy.sum(self._quantile_function(x=(y - x @ beta_var)))\n",
      "        objective = cvxpy.Minimize(objective_function)\n",
      "        problem = cvxpy.Problem(objective)\n",
      "        # Solve the problem. If solver is left as default, try optimal solver sugested by cvxpy.\n",
      "        # If other name is provided, try the name provided\n",
      "        # If these options fail, try default ECOS, OSQP, SCS options\n",
      "        try:\n",
      "            if self.solver == 'default':\n",
      "                problem.solve(warm_start=True)\n",
      "            else:\n",
      "                solver_dict = self._cvxpy_solver_options(solver=self.solver)\n",
      "                problem.solve(**solver_dict)\n",
      "        except (ValueError, cvxpy.error.SolverError):\n",
      "            logging.warning('Default solver failed. Using alternative options. Check solver and solver_stats for more '\n",
      "                            'details')\n",
      "            solver = ['ECOS', 'OSQP', 'SCS']\n",
      "            for elt in solver:\n",
      "                solver_dict = self._cvxpy_solver_options(solver=elt)\n",
      "                try:\n",
      "                    problem.solve(**solver_dict)\n",
      "                    if 'optimal' in problem.status:\n",
      "                        break\n",
      "                except (ValueError, cvxpy.error.SolverError):\n",
      "                    continue\n",
      "        self.solver_stats = problem.solver_stats\n",
      "        if problem.status in [\"infeasible\", \"unbounded\"]:\n",
      "            logging.warning('Optimization problem status failure')\n",
      "        beta_sol = beta_var.value\n",
      "        beta_sol[np.abs(beta_sol) < self.tol] = 0\n",
      "        return [beta_sol]\n",
      "\n",
      "    def lasso(self, x, y, param):\n",
      "        \"\"\"\n",
      "        Lasso penalized solver\n",
      "        \"\"\"\n",
      "        n, m = x.shape\n",
      "        # If we want an intercept, it adds a column of ones to the matrix x.\n",
      "        # Init_pen controls when the penalization starts, this way the intercept is not penalized\n",
      "        if self.intercept:\n",
      "            m = m + 1\n",
      "            x = np.c_[np.ones(n), x]\n",
      "            init_pen = 1\n",
      "        else:\n",
      "            init_pen = 0\n",
      "        # Define the objective function\n",
      "        lambda_param = cvxpy.Parameter(nonneg=True)\n",
      "        beta_var = cvxpy.Variable(m)\n",
      "        lasso_penalization = lambda_param * cvxpy.norm(beta_var[init_pen:], 1)\n",
      "        if self.model == 'lm':\n",
      "            objective_function = (1.0 / n) * cvxpy.sum_squares(y - x @ beta_var)\n",
      "        else:\n",
      "            objective_function = (1.0 / n) * cvxpy.sum(self._quantile_function(x=(y - x @ beta_var)))\n",
      "        objective = cvxpy.Minimize(objective_function + lasso_penalization)\n",
      "        problem = cvxpy.Problem(objective)\n",
      "        beta_sol_list = []\n",
      "        # Solve the problem iteratively for each parameter value\n",
      "        for lam in param:\n",
      "            lambda_param.value = lam\n",
      "            # Solve the problem. If solver is left as default, try optimal solver sugested by cvxpy.\n",
      "            # If other name is provided, try the name provided\n",
      "            # If these options fail, try default ECOS, OSQP, SCS options\n",
      "            try:\n",
      "                if self.solver == 'default':\n",
      "                    problem.solve(warm_start=True)\n",
      "                else:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=self.solver)\n",
      "                    problem.solve(**solver_dict)\n",
      "            except (ValueError, cvxpy.error.SolverError):\n",
      "                logging.warning(\n",
      "                    'Default solver failed. Using alternative options. Check solver and solver_stats for more '\n",
      "                    'details')\n",
      "                solver = ['ECOS', 'OSQP', 'SCS']\n",
      "                for elt in solver:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=elt)\n",
      "                    try:\n",
      "                        problem.solve(**solver_dict)\n",
      "                        if 'optimal' in problem.status:\n",
      "                            break\n",
      "                    except (ValueError, cvxpy.error.SolverError):\n",
      "                        continue\n",
      "            self.solver_stats = problem.solver_stats\n",
      "            if problem.status in [\"infeasible\", \"unbounded\"]:\n",
      "                logging.warning('Optimization problem status failure')\n",
      "            beta_sol = beta_var.value\n",
      "            beta_sol[np.abs(beta_sol) < self.tol] = 0\n",
      "            beta_sol_list.append(beta_sol)\n",
      "        logging.debug('Function finished without errors')\n",
      "        return beta_sol_list\n",
      "\n",
      "    def gl(self, x, y, group_index, param):\n",
      "        \"\"\"\n",
      "        Group lasso penalized solver\n",
      "        \"\"\"\n",
      "        n = x.shape[0]\n",
      "        # Check th group_index, find the unique groups, count how many vars are in each group (this is the group size)\n",
      "        group_index = np.asarray(group_index).astype(int)\n",
      "        unique_group_index = np.unique(group_index)\n",
      "        group_sizes, beta_var = self._num_beta_var_from_group_index(group_index)\n",
      "        num_groups = len(group_sizes)\n",
      "        model_prediction = 0\n",
      "        group_lasso_penalization = 0\n",
      "        # If the model has an intercept, we calculate the value of the model for the intercept group_index\n",
      "        # We start the penalization in inf_lim so if the model has an intercept, penalization starts after the intercept\n",
      "        inf_lim = 0\n",
      "        if self.intercept:\n",
      "            # Adds an element (referring to the intercept) to group_index, group_sizes, num groups\n",
      "            group_index = np.append(0, group_index)\n",
      "            unique_group_index = np.unique(group_index)\n",
      "            x = np.c_[np.ones(n), x]\n",
      "            group_sizes = [1] + group_sizes\n",
      "            beta_var = [cvxpy.Variable(1)] + beta_var\n",
      "            num_groups = num_groups + 1\n",
      "            # Compute model prediction for the intercept with no penalization\n",
      "            model_prediction = x[:, np.where(group_index == unique_group_index[0])[0]] @ beta_var[0]\n",
      "            inf_lim = 1\n",
      "        for i in range(inf_lim, num_groups):\n",
      "            model_prediction += x[:, np.where(group_index == unique_group_index[i])[0]] @ beta_var[i]\n",
      "            group_lasso_penalization += cvxpy.sqrt(group_sizes[i]) * cvxpy.norm(beta_var[i], 2)\n",
      "        if self.model == 'lm':\n",
      "            objective_function = (1.0 / n) * cvxpy.sum_squares(y - model_prediction)\n",
      "        else:\n",
      "            objective_function = (1.0 / n) * cvxpy.sum(self._quantile_function(x=(y - model_prediction)))\n",
      "        lambda_param = cvxpy.Parameter(nonneg=True)\n",
      "        objective = cvxpy.Minimize(objective_function + (lambda_param * group_lasso_penalization))\n",
      "        problem = cvxpy.Problem(objective)\n",
      "        beta_sol_list = []\n",
      "        # Solve the problem iteratively for each parameter value\n",
      "        for lam in param:\n",
      "            lambda_param.value = lam\n",
      "            # Solve the problem. If solver is left as default, try optimal solver sugested by cvxpy.\n",
      "            # If other name is provided, try the name provided\n",
      "            # If these options fail, try default ECOS, OSQP, SCS options\n",
      "            try:\n",
      "                if self.solver == 'default':\n",
      "                    problem.solve(warm_start=True)\n",
      "                else:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=self.solver)\n",
      "                    problem.solve(**solver_dict)\n",
      "            except (ValueError, cvxpy.error.SolverError):\n",
      "                logging.warning(\n",
      "                    'Default solver failed. Using alternative options. Check solver and solver_stats for more '\n",
      "                    'details')\n",
      "                solver = ['ECOS', 'OSQP', 'SCS']\n",
      "                for elt in solver:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=elt)\n",
      "                    try:\n",
      "                        problem.solve(**solver_dict)\n",
      "                        if 'optimal' in problem.status:\n",
      "                            break\n",
      "                    except (ValueError, cvxpy.error.SolverError):\n",
      "                        continue\n",
      "            self.solver_stats = problem.solver_stats\n",
      "            if problem.status in [\"infeasible\", \"unbounded\"]:\n",
      "                logging.warning('Optimization problem status failure')\n",
      "            beta_sol = np.concatenate([b.value for b in beta_var], axis=0)\n",
      "            beta_sol[np.abs(beta_sol) < self.tol] = 0\n",
      "            beta_sol_list.append(beta_sol)\n",
      "        return beta_sol_list\n",
      "\n",
      "    def sgl(self, x, y, group_index, param):\n",
      "        \"\"\"\n",
      "        Sparse group lasso penalized solver\n",
      "        \"\"\"\n",
      "        n = x.shape[0]\n",
      "        # Check th group_index, find the unique groups, count how many vars are in each group (this is the group size)\n",
      "        group_index = np.asarray(group_index).astype(int)\n",
      "        unique_group_index = np.unique(group_index)\n",
      "        group_sizes, beta_var = self._num_beta_var_from_group_index(group_index)\n",
      "        num_groups = len(group_sizes)\n",
      "        model_prediction = 0\n",
      "        lasso_penalization = 0\n",
      "        group_lasso_penalization = 0\n",
      "        # If the model has an intercept, we calculate the value of the model for the intercept group_index\n",
      "        # We start the penalization in inf_lim so if the model has an intercept, penalization starts after the intercept\n",
      "        inf_lim = 0\n",
      "        if self.intercept:\n",
      "            group_index = np.append(0, group_index)\n",
      "            unique_group_index = np.unique(group_index)\n",
      "            x = np.c_[np.ones(n), x]\n",
      "            group_sizes = [1] + group_sizes\n",
      "            beta_var = [cvxpy.Variable(1)] + beta_var\n",
      "            num_groups = num_groups + 1\n",
      "            model_prediction = x[:, np.where(group_index == unique_group_index[0])[0]] @ beta_var[0]\n",
      "            inf_lim = 1\n",
      "        for i in range(inf_lim, num_groups):\n",
      "            model_prediction += x[:, np.where(group_index == unique_group_index[i])[0]] @ beta_var[i]\n",
      "            group_lasso_penalization += cvxpy.sqrt(group_sizes[i]) * cvxpy.norm(beta_var[i], 2)\n",
      "            lasso_penalization += cvxpy.norm(beta_var[i], 1)\n",
      "        if self.model == 'lm':\n",
      "            objective_function = (1.0 / n) * cvxpy.sum_squares(y - model_prediction)\n",
      "        else:\n",
      "            objective_function = (1.0 / n) * cvxpy.sum(self._quantile_function(x=(y - model_prediction)))\n",
      "        lasso_param = cvxpy.Parameter(nonneg=True)\n",
      "        grp_lasso_param = cvxpy.Parameter(nonneg=True)\n",
      "        objective = cvxpy.Minimize(objective_function +\n",
      "                                   (grp_lasso_param * group_lasso_penalization) +\n",
      "                                   (lasso_param * lasso_penalization))\n",
      "        problem = cvxpy.Problem(objective)\n",
      "        beta_sol_list = []\n",
      "        # Solve the problem iteratively for each parameter value\n",
      "        for lam, al in param:\n",
      "            lasso_param.value = lam * al\n",
      "            grp_lasso_param.value = lam * (1 - al)\n",
      "            # Solve the problem. If solver is left as default, try optimal solver sugested by cvxpy.\n",
      "            # If other name is provided, try the name provided\n",
      "            # If these options fail, try default ECOS, OSQP, SCS options\n",
      "            try:\n",
      "                if self.solver == 'default':\n",
      "                    problem.solve(warm_start=True)\n",
      "                else:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=self.solver)\n",
      "                    problem.solve(**solver_dict)\n",
      "            except (ValueError, cvxpy.error.SolverError):\n",
      "                logging.warning(\n",
      "                    'Default solver failed. Using alternative options. Check solver and solver_stats for more '\n",
      "                    'details')\n",
      "                solver = ['ECOS', 'OSQP', 'SCS']\n",
      "                for elt in solver:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=elt)\n",
      "                    try:\n",
      "                        problem.solve(**solver_dict)\n",
      "                        if 'optimal' in problem.status:\n",
      "                            break\n",
      "                    except (ValueError, cvxpy.error.SolverError):\n",
      "                        continue\n",
      "            self.solver_stats = problem.solver_stats\n",
      "            if problem.status in [\"infeasible\", \"unbounded\"]:\n",
      "                logging.warning('Optimization problem status failure')\n",
      "            beta_sol = np.concatenate([b.value for b in beta_var], axis=0)\n",
      "            beta_sol[np.abs(beta_sol) < self.tol] = 0\n",
      "            beta_sol_list.append(beta_sol)\n",
      "        return beta_sol_list\n",
      "\n",
      "    def alasso(self, x, y, param):\n",
      "        \"\"\"\n",
      "        Lasso penalized solver\n",
      "        \"\"\"\n",
      "        n, m = x.shape\n",
      "        # If we want an intercept, it adds a column of ones to the matrix x.\n",
      "        # Init_pen controls when the penalization starts, this way the intercept is not penalized\n",
      "        if self.intercept:\n",
      "            m = m + 1\n",
      "            x = np.c_[np.ones(n), x]\n",
      "            init_pen = 1\n",
      "        else:\n",
      "            init_pen = 0\n",
      "        # Define the objective function\n",
      "        l_weights_param = cvxpy.Parameter(m, nonneg=True)\n",
      "        beta_var = cvxpy.Variable(m)\n",
      "        lasso_penalization = cvxpy.norm(l_weights_param[init_pen:].T @ cvxpy.abs(beta_var[init_pen:]), 1)\n",
      "        if self.model == 'lm':\n",
      "            objective_function = (1.0 / n) * cvxpy.sum_squares(y - x @ beta_var)\n",
      "        else:\n",
      "            objective_function = (1.0 / n) * cvxpy.sum(self._quantile_function(x=(y - x @ beta_var)))\n",
      "        objective = cvxpy.Minimize(objective_function + lasso_penalization)\n",
      "        problem = cvxpy.Problem(objective)\n",
      "        beta_sol_list = []\n",
      "        # Solve the problem iteratively for each parameter value\n",
      "        for lam, lw in param:\n",
      "            l_weights_param.value = lam * lw\n",
      "            # Solve the problem. If solver is left as default, try optimal solver sugested by cvxpy.\n",
      "            # If other name is provided, try the name provided\n",
      "            # If these options fail, try default ECOS, OSQP, SCS options\n",
      "            try:\n",
      "                if self.solver == 'default':\n",
      "                    problem.solve(warm_start=True)\n",
      "                else:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=self.solver)\n",
      "                    problem.solve(**solver_dict)\n",
      "            except (ValueError, cvxpy.error.SolverError):\n",
      "                logging.warning(\n",
      "                    'Default solver failed. Using alternative options. Check solver and solver_stats for more '\n",
      "                    'details')\n",
      "                solver = ['ECOS', 'OSQP', 'SCS']\n",
      "                for elt in solver:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=elt)\n",
      "                    try:\n",
      "                        problem.solve(**solver_dict)\n",
      "                        if 'optimal' in problem.status:\n",
      "                            break\n",
      "                    except (ValueError, cvxpy.error.SolverError):\n",
      "                        continue\n",
      "            self.solver_stats = problem.solver_stats\n",
      "            if problem.status in [\"infeasible\", \"unbounded\"]:\n",
      "                logging.warning('Optimization problem status failure')\n",
      "            beta_sol = beta_var.value\n",
      "            beta_sol[np.abs(beta_sol) < self.tol] = 0\n",
      "            beta_sol_list.append(beta_sol)\n",
      "        logging.debug('Function finished without errors')\n",
      "        return beta_sol_list\n",
      "\n",
      "    def agl(self, x, y, group_index, param):\n",
      "        \"\"\"\n",
      "        Group lasso penalized solver\n",
      "        \"\"\"\n",
      "        n = x.shape[0]\n",
      "        # Check th group_index, find the unique groups, count how many vars are in each group (this is the group size)\n",
      "        group_index = np.asarray(group_index).astype(int)\n",
      "        unique_group_index = np.unique(group_index)\n",
      "        group_sizes, beta_var = self._num_beta_var_from_group_index(group_index)\n",
      "        num_groups = len(group_sizes)\n",
      "        model_prediction = 0\n",
      "        group_lasso_penalization = 0\n",
      "        # If the model has an intercept, we calculate the value of the model for the intercept group_index\n",
      "        # We start the penalization in inf_lim so if the model has an intercept, penalization starts after the intercept\n",
      "        inf_lim = 0\n",
      "        if self.intercept:\n",
      "            # Adds an element (referring to the intercept) to group_index, group_sizes, num groups\n",
      "            group_index = np.append(0, group_index)\n",
      "            unique_group_index = np.unique(group_index)\n",
      "            x = np.c_[np.ones(n), x]\n",
      "            group_sizes = [1] + group_sizes\n",
      "            beta_var = [cvxpy.Variable(1)] + beta_var\n",
      "            num_groups = num_groups + 1\n",
      "            # Compute model prediction for the intercept with no penalization\n",
      "            model_prediction = x[:, np.where(group_index == unique_group_index[0])[0]] @ beta_var[0]\n",
      "            inf_lim = 1\n",
      "        gl_weights_param = cvxpy.Parameter(num_groups, nonneg=True)\n",
      "        for i in range(inf_lim, num_groups):\n",
      "            model_prediction += x[:, np.where(group_index == unique_group_index[i])[0]] @ beta_var[i]\n",
      "            group_lasso_penalization += cvxpy.sqrt(group_sizes[i]) * gl_weights_param[i] * cvxpy.norm(beta_var[i], 2)\n",
      "        if self.model == 'lm':\n",
      "            objective_function = (1.0 / n) * cvxpy.sum_squares(y - model_prediction)\n",
      "        else:\n",
      "            objective_function = (1.0 / n) * cvxpy.sum(self._quantile_function(x=(y - model_prediction)))\n",
      "        objective = cvxpy.Minimize(objective_function + group_lasso_penalization)\n",
      "        problem = cvxpy.Problem(objective)\n",
      "        beta_sol_list = []\n",
      "        # Solve the problem iteratively for each parameter value\n",
      "        for lam, gl in param:\n",
      "            gl_weights_param.value = lam * gl\n",
      "            # Solve the problem. If solver is left as default, try optimal solver sugested by cvxpy.\n",
      "            # If other name is provided, try the name provided\n",
      "            # If these options fail, try default ECOS, OSQP, SCS options\n",
      "            try:\n",
      "                if self.solver == 'default':\n",
      "                    problem.solve(warm_start=True)\n",
      "                else:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=self.solver)\n",
      "                    problem.solve(**solver_dict)\n",
      "            except (ValueError, cvxpy.error.SolverError):\n",
      "                logging.warning(\n",
      "                    'Default solver failed. Using alternative options. Check solver and solver_stats for more '\n",
      "                    'details')\n",
      "                solver = ['ECOS', 'OSQP', 'SCS']\n",
      "                for elt in solver:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=elt)\n",
      "                    try:\n",
      "                        problem.solve(**solver_dict)\n",
      "                        if 'optimal' in problem.status:\n",
      "                            break\n",
      "                    except (ValueError, cvxpy.error.SolverError):\n",
      "                        continue\n",
      "            self.solver_stats = problem.solver_stats\n",
      "            if problem.status in [\"infeasible\", \"unbounded\"]:\n",
      "                logging.warning('Optimization problem status failure')\n",
      "            beta_sol = np.concatenate([b.value for b in beta_var], axis=0)\n",
      "            beta_sol[np.abs(beta_sol) < self.tol] = 0\n",
      "            beta_sol_list.append(beta_sol)\n",
      "        return beta_sol_list\n",
      "\n",
      "    def asgl(self, x, y, group_index, param):\n",
      "        \"\"\"\n",
      "        adaptive sparse group lasso penalized solver\n",
      "        \"\"\"\n",
      "        n, m = x.shape\n",
      "        # Check th group_index, find the unique groups, count how many vars are in each group (this is the group size)\n",
      "        group_index = np.asarray(group_index).astype(int)\n",
      "        unique_group_index = np.unique(group_index)\n",
      "        group_sizes, beta_var = self._num_beta_var_from_group_index(group_index)\n",
      "        num_groups = len(group_sizes)\n",
      "        model_prediction = 0\n",
      "        alasso_penalization = 0\n",
      "        a_group_lasso_penalization = 0\n",
      "        # If the model has an intercept, we calculate the value of the model for the intercept group_index\n",
      "        # We start the penalization in inf_lim so if the model has an intercept, penalization starts after the intercept\n",
      "        inf_lim = 0\n",
      "        if self.intercept:\n",
      "            group_index = np.append(0, group_index)\n",
      "            unique_group_index = np.unique(group_index)\n",
      "            x = np.c_[np.ones(n), x]\n",
      "            m = m + 1\n",
      "            group_sizes = [1] + group_sizes\n",
      "            beta_var = [cvxpy.Variable(1)] + beta_var\n",
      "            num_groups = num_groups + 1\n",
      "            model_prediction = x[:, np.where(group_index == unique_group_index[0])[0]] @ beta_var[0]\n",
      "            inf_lim = 1\n",
      "        l_weights_param = cvxpy.Parameter(m, nonneg=True)\n",
      "        gl_weights_param = cvxpy.Parameter(num_groups, nonneg=True)\n",
      "        for i in range(inf_lim, num_groups):\n",
      "            model_prediction += x[:, np.where(group_index == unique_group_index[i])[0]] @ beta_var[i]\n",
      "            a_group_lasso_penalization += cvxpy.sqrt(group_sizes[i]) * gl_weights_param[i] * cvxpy.norm(beta_var[i], 2)\n",
      "            alasso_penalization += l_weights_param[np.where(group_index ==\n",
      "                                                            unique_group_index[i])[0]].T @ cvxpy.abs(beta_var[i])\n",
      "        if self.model == 'lm':\n",
      "            objective_function = (1.0 / n) * cvxpy.sum_squares(y - model_prediction)\n",
      "        else:\n",
      "            objective_function = (1.0 / n) * cvxpy.sum(self._quantile_function(x=(y - model_prediction)))\n",
      "        objective = cvxpy.Minimize(objective_function +\n",
      "                                   a_group_lasso_penalization +\n",
      "                                   alasso_penalization)\n",
      "        problem = cvxpy.Problem(objective)\n",
      "        beta_sol_list = []\n",
      "        # Solve the problem iteratively for each parameter value\n",
      "        for lam, al, lw, glw in param:\n",
      "            l_weights_param.value = lw * lam * al\n",
      "            gl_weights_param.value = glw * lam * (1 - al)\n",
      "            # Solve the problem. If solver is left as default, try optimal solver sugested by cvxpy.\n",
      "            # If other name is provided, try the name provided\n",
      "            # If these options fail, try default ECOS, OSQP, SCS options\n",
      "            try:\n",
      "                if self.solver == 'default':\n",
      "                    problem.solve(warm_start=True)\n",
      "                else:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=self.solver)\n",
      "                    problem.solve(**solver_dict)\n",
      "            except (ValueError, cvxpy.error.SolverError):\n",
      "                logging.warning(\n",
      "                    'Default solver failed. Using alternative options. Check solver and solver_stats for more '\n",
      "                    'details')\n",
      "                solver = ['ECOS', 'OSQP', 'SCS']\n",
      "                for elt in solver:\n",
      "                    solver_dict = self._cvxpy_solver_options(solver=elt)\n",
      "                    try:\n",
      "                        problem.solve(**solver_dict)\n",
      "                        if 'optimal' in problem.status:\n",
      "                            break\n",
      "                    except (ValueError, cvxpy.error.SolverError):\n",
      "                        continue\n",
      "            self.solver_stats = problem.solver_stats\n",
      "            if problem.status in [\"infeasible\", \"unbounded\"]:\n",
      "                logging.warning('Optimization problem status failure')\n",
      "            beta_sol = np.concatenate([b.value for b in beta_var], axis=0)\n",
      "            beta_sol[np.abs(beta_sol) < self.tol] = 0\n",
      "            beta_sol_list.append(beta_sol)\n",
      "        return beta_sol_list\n",
      "\n",
      "    # PARALLEL CODE ###################################################################################################\n",
      "\n",
      "    def _parallel_execution(self, x, y, param, group_index=None):\n",
      "        \"\"\"\n",
      "        Parallel implementation of the solvers\n",
      "        \"\"\"\n",
      "        if self.num_cores is None:\n",
      "            # If the number of cores is not defined by user, use all available minus 1\n",
      "            num_chunks = mp.cpu_count() - 1\n",
      "        else:\n",
      "            num_chunks = np.min((self.num_cores, mp.cpu_count()))\n",
      "        # Divide the list of parameter values into as many chunks as threads that we want to use in parallel\n",
      "        tmp_group_index_chunks = np.array_split(range(len(param)), num_chunks)\n",
      "        # If the number of parameters is shorter than the number of threads, delete the empty groups\n",
      "        group_index_chunks = []\n",
      "        for elt in tmp_group_index_chunks:\n",
      "            if elt.size != 0:\n",
      "                group_index_chunks.append(elt)\n",
      "        # chunks is a list with as many elements as num_chunks\n",
      "        # Each element of the list is another list of tuples of parameter values\n",
      "        chunks = []\n",
      "        for elt in group_index_chunks:\n",
      "            chunks.append(param[elt[0]:(1 + elt[-1])])\n",
      "        # Solve problem in parallel\n",
      "        pool = mp.Pool(num_chunks)\n",
      "        if self.penalization in ['lasso', 'alasso']:\n",
      "            global_results = pool.map(functools.partial(getattr(self, self._get_solver_names()), x, y), chunks)\n",
      "        else:\n",
      "            global_results = pool.map(functools.partial(getattr(self, self._get_solver_names()), x, y, group_index),\n",
      "                                      chunks)\n",
      "        pool.close()\n",
      "        pool.join()\n",
      "        # Re-build the output of the function\n",
      "        beta_sol_list = []\n",
      "        if len(param) < num_chunks:\n",
      "            limit = len(param)\n",
      "        else:\n",
      "            limit = num_chunks\n",
      "        for i in range(limit):\n",
      "            beta_sol_list.extend(global_results[i])\n",
      "        return beta_sol_list\n",
      "\n",
      "    # FIT METHOD ######################################################################################################\n",
      "\n",
      "    def _get_solver_names(self):\n",
      "        if 'asgl' in self.penalization:\n",
      "            return 'asgl'\n",
      "        else:\n",
      "            return self.penalization\n",
      "\n",
      "    def fit(self, x, y, group_index=None):\n",
      "        \"\"\"\n",
      "        Main function of the module. Given a model, penalization and parameter values specified in the class definition,\n",
      "        this function solves the model and produces the regression coefficients\n",
      "        \"\"\"\n",
      "        param = self._preprocessing()\n",
      "        if self.penalization is None:\n",
      "            self.coef_ = self.unpenalized_solver(x=x, y=y)\n",
      "        else:\n",
      "            if self.parallel is False:\n",
      "                if self.penalization in ['lasso', 'alasso']:\n",
      "                    self.coef_ = getattr(self, self._get_solver_names())(x=x, y=y, param=param)\n",
      "                else:\n",
      "                    self.coef_ = getattr(self, self._get_solver_names())(x=x, y=y, param=param,\n",
      "                                                                         group_index=group_index)\n",
      "            else:\n",
      "                self.coef_ = self._parallel_execution(x=x, y=y, param=param, group_index=group_index)\n",
      "\n",
      "    # PREDICTION METHOD ###############################################################################################\n",
      "\n",
      "    def predict(self, x_new):\n",
      "        \"\"\"\n",
      "        To be executed after fitting a model. Given a new dataset, this function produces predictions for that data\n",
      "        considering the different model coefficients output provided by function fit\n",
      "        \"\"\"\n",
      "        if self.intercept:\n",
      "            x_new = np.c_[np.ones(x_new.shape[0]), x_new]\n",
      "        if x_new.shape[1] != len(self.coef_[0]):\n",
      "            logging.error('Model dimension and new data dimension does not match')\n",
      "            raise ValueError('Model dimension and new data dimension does not match')\n",
      "        # Store predictions in a list\n",
      "        prediction_list = []\n",
      "        for elt in self.coef_:\n",
      "            prediction_list.append(np.dot(x_new, elt))\n",
      "        return prediction_list\n",
      "\n",
      "    # NUMBER OF PARAMETERS ############################################################################################\n",
      "\n",
      "    def _num_parameters(self):\n",
      "        \"\"\"\n",
      "        retrieves the number of parameters to be considered in a model\n",
      "        Output: tuple [num_models, n_lambda, n_alpha, n_l_weights, n_gl_weights] where\n",
      "        - num_models: total number of models to be solved for the grid of parameters given\n",
      "        - n_lambda: number of different lambda1 values\n",
      "        - n_alpha: number of different alpha values\n",
      "        - n_l_weights: number of different weights for the lasso part of the asgl (or asgl_lasso) penalizations\n",
      "        - n_gl_weights: number of different weights for the lasso part of the asgl (or asgl_gl) penalizations\n",
      "        \"\"\"\n",
      "        # Run the input_checker to verify that the inputs have the correct format\n",
      "        if self._input_checker() is False:\n",
      "            logging.error('incorrect input parameters')\n",
      "            raise ValueError('incorrect input parameters')\n",
      "        if self.penalization is None:\n",
      "            # See meaning of each element in the \"else\" result statement.\n",
      "            result = dict(num_models=1,\n",
      "                          n_lambda=None,\n",
      "                          n_alpha=None,\n",
      "                          n_lasso_weights=None,\n",
      "                          n_gl_weights=None)\n",
      "        else:\n",
      "            n_lambda, drop = self._preprocessing_lambda()\n",
      "            n_alpha, drop = self._preprocessing_alpha()\n",
      "            n_lasso_weights, drop = self._preprocessing_weights(self.lasso_weights)\n",
      "            n_gl_weights, drop = self._preprocessing_weights(self.gl_weights)\n",
      "            list_param = [n_lambda, n_alpha, n_lasso_weights, n_gl_weights]\n",
      "            list_param_no_none = [elt for elt in list_param if elt is not None]\n",
      "            num_models = np.prod(list_param_no_none)\n",
      "            result = dict(num_models=num_models,\n",
      "                          n_lambda=n_lambda,\n",
      "                          n_alpha=n_alpha,\n",
      "                          n_lasso_weights=n_lasso_weights,\n",
      "                          n_gl_weights=n_gl_weights)\n",
      "        return result\n",
      "\n",
      "    def _retrieve_parameters_idx(self, param_index):\n",
      "        \"\"\"\n",
      "        Given an index for the param iterable output from _preprocessing function, this function returns a tupple\n",
      "        with the index of the value of each parameter.\n",
      "        Example: Solving an adaptive sparse group lasso model with 5 values for lambda1, 4 values for alpha,\n",
      "                 3 possible lasso weights and 3 possible group lasso weights yields in a grid search on\n",
      "                 5*4*3*3=180 parameters.\n",
      "                 Inputing param_index=120 (out of the 180 possible values)in this function will output the\n",
      "                 lambda, alpha, and weights index for such value\n",
      "        If the penalization under consideration does not include any of the required parameters (for example, if we are\n",
      "        solving an sparse group lasso model, we do not consider adaptive weights), the output regarding the non used\n",
      "        parameters are set to be None.\n",
      "        \"\"\"\n",
      "        number_parameters = self._num_parameters()\n",
      "        n_models, n_lambda, n_alpha, n_l_weights, n_gl_weights = [number_parameters[elt] for elt in number_parameters]\n",
      "        if param_index > n_models:\n",
      "            string = f'param_index should be smaller or equal than the number of models solved. n_models={n_models}, ' \\\n",
      "                     f'param_index={param_index}'\n",
      "            logging.error(string)\n",
      "            raise ValueError(string)\n",
      "        # If penalization is None, all parameters are set to None\n",
      "        if self.penalization is None:\n",
      "            result = [None, None, None, None]\n",
      "        # If penalization is lasso or gl, there is only one parameter, so param_index = position of that parameter\n",
      "        elif self.penalization in ['lasso', 'gl']:\n",
      "            result = [param_index, None, None, None]\n",
      "        # If penalization is sgl, there are two parameters and two None\n",
      "        elif self.penalization == 'sgl':\n",
      "            parameter_matrix = np.arange(n_models).reshape((n_lambda, n_alpha))\n",
      "            parameter_idx = np.where(parameter_matrix == param_index)\n",
      "            result = [parameter_idx[0][0], parameter_idx[1][0], None, None]\n",
      "        elif self.penalization == 'alasso':\n",
      "            parameter_matrix = np.arange(n_models).reshape((n_lambda, n_l_weights))\n",
      "            parameter_idx = np.where(parameter_matrix == param_index)\n",
      "            result = [parameter_idx[0][0], None, parameter_idx[1][0], None]\n",
      "        elif self.penalization == 'agl':\n",
      "            parameter_matrix = np.arange(n_models).reshape((n_lambda, n_gl_weights))\n",
      "            parameter_idx = np.where(parameter_matrix == param_index)\n",
      "            result = [parameter_idx[0][0], None, None, parameter_idx[1][0]]\n",
      "        else:\n",
      "            parameter_matrix = np.arange(n_models).reshape((n_lambda, n_alpha, n_l_weights, n_gl_weights))\n",
      "            parameter_idx = np.where(parameter_matrix == param_index)\n",
      "            result = [parameter_idx[0][0], parameter_idx[1][0],\n",
      "                      parameter_idx[2][0], parameter_idx[3][0]]\n",
      "        return result\n",
      "\n",
      "    def retrieve_parameters_value(self, param_index):\n",
      "        \"\"\"\n",
      "        Converts the index output from retrieve_parameters_idx into the actual numerical value of the parameters.\n",
      "        Outputs None if the parameter was not used in the model formulation.\n",
      "        To be executed after fit method.\n",
      "        \"\"\"\n",
      "        param_index = self._retrieve_parameters_idx(param_index)\n",
      "        result = [param[idx] if idx is not None else None for idx, param in\n",
      "                  zip(param_index, [self.lambda1, self.alpha, self.lasso_weights, self.gl_weights])]\n",
      "        result = dict(lambda1=result[0],\n",
      "                      alpha=result[1],\n",
      "                      lasso_weights=result[2],\n",
      "                      gl_weights=result[3])\n",
      "        return result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(ASGL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65946db",
   "metadata": {},
   "outputs": [],
   "source": [
    " def lasso(self, x, y, param):\n",
    "        \"\"\"\n",
    "        Lasso penalized solver\n",
    "        \"\"\"\n",
    "        n, m = x.shape\n",
    "        # If we want an intercept, it adds a column of ones to the matrix x.\n",
    "        # Init_pen controls when the penalization starts, this way the intercept is not penalized\n",
    "        if self.intercept:\n",
    "            m = m + 1\n",
    "            x = np.c_[np.ones(n), x]\n",
    "            init_pen = 1\n",
    "        else:\n",
    "            init_pen = 0\n",
    "        # Define the objective function\n",
    "        lambda_param = cvxpy.Parameter(nonneg=True)\n",
    "        beta_var = cvxpy.Variable(m)\n",
    "        lasso_penalization = lambda_param * cvxpy.norm(beta_var[init_pen:], 1)\n",
    "        if self.model == 'lm':\n",
    "            objective_function = (1.0 / n) * cvxpy.sum_squares(y - x @ beta_var)\n",
    "        else:\n",
    "            objective_function = (1.0 / n) * cvxpy.sum(self._quantile_function(x=(y - x @ beta_var)))\n",
    "        objective = cvxpy.Minimize(objective_function + lasso_penalization)\n",
    "        problem = cvxpy.Problem(objective)\n",
    "        beta_sol_list = []\n",
    "        # Solve the problem iteratively for each parameter value\n",
    "        for lam in param:\n",
    "            lambda_param.value = lam\n",
    "            # Solve the problem. If solver is left as default, try optimal solver sugested by cvxpy.\n",
    "            # If other name is provided, try the name provided\n",
    "            # If these options fail, try default ECOS, OSQP, SCS options\n",
    "            try:\n",
    "                if self.solver == 'default':\n",
    "                    problem.solve(warm_start=True)\n",
    "                else:\n",
    "                    solver_dict = self._cvxpy_solver_options(solver=self.solver)\n",
    "                    problem.solve(**solver_dict)\n",
    "            except (ValueError, cvxpy.error.SolverError):\n",
    "                logging.warning(\n",
    "                    'Default solver failed. Using alternative options. Check solver and solver_stats for more '\n",
    "                    'details')\n",
    "                solver = ['ECOS', 'OSQP', 'SCS']\n",
    "                for elt in solver:\n",
    "                    solver_dict = self._cvxpy_solver_options(solver=elt)\n",
    "                    try:\n",
    "                        problem.solve(**solver_dict)\n",
    "                        if 'optimal' in problem.status:\n",
    "                            break\n",
    "                    except (ValueError, cvxpy.error.SolverError):\n",
    "                        continue\n",
    "            self.solver_stats = problem.solver_stats\n",
    "            if problem.status in [\"infeasible\", \"unbounded\"]:\n",
    "                logging.warning('Optimization problem status failure')\n",
    "            beta_sol = beta_var.value\n",
    "            beta_sol[np.abs(beta_sol) < self.tol] = 0\n",
    "            beta_sol_list.append(beta_sol)\n",
    "        logging.debug('Function finished without errors')\n",
    "        return beta_sol_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8516e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pycasso\n",
    "import pycasso # penalty : mcp 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e99f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c260323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41949765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0670d296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471a430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
